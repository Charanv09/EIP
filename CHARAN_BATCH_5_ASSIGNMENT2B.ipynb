{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Read input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : \n",
      " [[1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [0 1 0 1]]\n",
      "y : \n",
      " [[1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "y = np.array([[1],[1],[0]])\n",
    "print(\"X : \\n\", X)\n",
    "print(\"y : \\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Initialize weights and biases with random values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: \n",
      " [[0.96301645 0.90691287 0.16381665]\n",
      " [0.12070335 0.01951863 0.18193523]\n",
      " [0.39742738 0.62332728 0.1114101 ]\n",
      " [0.13471936 0.86938414 0.61156002]]\n",
      "baises: \n",
      " [[0.2848115  0.72784961 0.56603158]]\n",
      "Hidden layer Weights: \n",
      " [[0.92378989]\n",
      " [0.29286508]\n",
      " [0.23150473]]\n",
      "Hidden layer Bias:\n",
      " [[0.74998388]]\n"
     ]
    }
   ],
   "source": [
    "wh = np.random.rand(4,3)\n",
    "print(\"Weights: \\n\", wh)\n",
    "bh=np.random.rand(1,3)\n",
    "print(\"baises: \\n\", bh)\n",
    "wout=np.random.random((3,1))\n",
    "print(\"Hidden layer Weights: \\n\", wout)\n",
    "bout=np.random.random((1,1))\n",
    "print(\"Hidden layer Bias:\\n\", bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Calculate hidden layer input:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden_layer_input = matrix_dot_product(X,wh) + bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_layer_input: \n",
      " [[1.64525533 2.25808977 0.84125833]\n",
      " [1.77997468 3.1274739  1.45281836]\n",
      " [0.5402342  1.61675238 1.35952683]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_input = (np.dot(X,wh))+bh\n",
    "print(\"hidden_layer_input: \\n\",hidden_layer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Perform non-linear transformation on hidden linear input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hiddenlayer_activations = sigmoid(hidden_layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiddenlayer_activations: \n",
      " [[0.83824876 0.90534606 0.69873017]\n",
      " [0.85569374 0.9580119  0.8104318 ]\n",
      " [0.6318669  0.83434676 0.79568278]]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "print(\"hiddenlayer_activations: \\n\",hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Perform linear and non-linear transformation of hidden layer activation at output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_layer_input = matrix_dot_product (hiddenlayer_activations * wout ) + bout output = sigmoid(output_layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_layer_input: \n",
      " [[1.95125321]\n",
      " [2.00865214]\n",
      " [1.7622515 ]]\n"
     ]
    }
   ],
   "source": [
    "output_layer_input = hiddenlayer_activations.dot(wout) + bout\n",
    "print(\"output_layer_input: \\n\", output_layer_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: \n",
      " [[0.87558323]\n",
      " [0.88170251]\n",
      " [0.85349142]]\n"
     ]
    }
   ],
   "source": [
    "output = sigmoid(output_layer_input)\n",
    "print(\"output: \\n\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Calculate gradient of Error(E) at output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E = y-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      " [[ 0.12441677]\n",
      " [ 0.11829749]\n",
      " [-0.85349142]]\n"
     ]
    }
   ],
   "source": [
    "E = y - output\n",
    "print(\"Error: \\n\",E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Compute slope at output and hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slope_output_layer= derivatives_sigmoid(output)\n",
    "\n",
    "Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope_output_layer: \n",
      " [[0.10893724]\n",
      " [0.1043032 ]\n",
      " [0.12504382]]\n",
      "Slope_hidden_layer: \n",
      " [[0.13558777 0.08569457 0.21050632]\n",
      " [0.12348196 0.0402251  0.1536321 ]\n",
      " [0.23261112 0.13821225 0.16257169]]\n"
     ]
    }
   ],
   "source": [
    "def derivatives_sigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "Slope_output_layer=derivatives_sigmoid(output)\n",
    "print(\"Slope_output_layer: \\n\", Slope_output_layer)\n",
    "\n",
    "Slope_hidden_layer=derivatives_sigmoid(hiddenlayer_activations)\n",
    "print(\"Slope_hidden_layer: \\n\", Slope_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Compute delta at output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_output = E * slope_output_layer*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta ouput: \n",
      " [[ 0.00135536]\n",
      " [ 0.00123388]\n",
      " [-0.01067238]]\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "\n",
    "d_output = E * Slope_output_layer * lr\n",
    "print(\"delta ouput: \\n\",d_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Calculate Error at hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error_at_hidden_layer = matrix_dot_product(d_output, wout.Transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at hidden layer: \n",
      " [[ 0.00125207  0.00039694  0.00031377]\n",
      " [ 0.00113985  0.00036136  0.00028565]\n",
      " [-0.00985904 -0.00312557 -0.00247071]]\n"
     ]
    }
   ],
   "source": [
    "Error_at_hidden_layer=d_output * wout.transpose()\n",
    "print(\"Error at hidden layer: \\n\",Error_at_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Compute delta at hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta at hidden layer: \n",
      " [[ 1.69765345e-04  3.40154486e-05  6.60511393e-05]\n",
      " [ 1.40750479e-04  1.45357648e-05  4.38848862e-05]\n",
      " [-2.29332212e-03 -4.31991797e-04 -4.01667021e-04]]\n"
     ]
    }
   ],
   "source": [
    "d_hiddenlayer=Error_at_hidden_layer*Slope_hidden_layer\n",
    "print(\"delta at hidden layer: \\n\",d_hiddenlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Update weight at both output and hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wout = wout + matrix_dot_product (hiddenlayer_activations.Transpose, d_output) * learning_rate\n",
    "\n",
    "wh = wh+ matrix_dot_product (X.Transpose,d_hiddenlayer) * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wout : \n",
      " [[0.92333474]\n",
      " [0.29221555]\n",
      " [0.23085025]]\n",
      "wh: \n",
      " [[0.9630475  0.90691773 0.16382765]\n",
      " [0.12047402 0.01947543 0.18189507]\n",
      " [0.39745843 0.62333214 0.1114211 ]\n",
      " [0.1345041  0.86934239 0.61152425]]\n"
     ]
    }
   ],
   "source": [
    "wout=wout+(hiddenlayer_activations.transpose().dot(d_output)) * lr\n",
    "print(\"wout : \\n\", wout)\n",
    "\n",
    "wh=wh+X.transpose().dot(d_hiddenlayer) * lr\n",
    "print(\"wh: \\n\",wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Update biases at both output and hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bh = bh + sum(d_hiddenlayer, axis=0) * learning_rate\n",
    "\n",
    "bout = bout + sum(d_output, axis=0)*learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bh: \n",
      " [[0.28461322 0.72781127 0.5660024 ]]\n",
      "bout: \n",
      " [[0.74917557]]\n"
     ]
    }
   ],
   "source": [
    "bh = bh + np.sum(d_hiddenlayer, axis=0) * lr\n",
    "print(\"bh: \\n\",bh)\n",
    "\n",
    "bout = bout + np.sum(d_output, axis=0) * lr\n",
    "print(\"bout: \\n\", bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
